model:
  latent_dim: 2

training:
  learning_rate: 1e-3
  batch_size: 32
  epochs: 100
  workers: 4
  weight_decay: 0.0000
  gradient_accumulation_steps: 8
  use_schedule: True
